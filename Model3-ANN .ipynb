{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15cf8f-9a69-4890-a68a-f431150b3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3- ANN -MLP Feedforward Network\n",
    "# Load the dataset\n",
    "path= \"/content/sample_data/Anonymized Dataset for Info Science MS.xlsx\"\n",
    "df = pd.read_excel(path)\n",
    "\n",
    "#Lets imput missing values as missing values %= 10860/62512= 17.37% which is significant portion of the data.\n",
    "#Hence we will impute the missing values rather than discarding them\n",
    "\n",
    "\n",
    "df['TermGPA'] = df['TermGPA'].fillna(df['TermGPA'].mean())\n",
    "df['CumulativeGPA'] = df['CumulativeGPA'].fillna(df['CumulativeGPA'].mean())\n",
    "\n",
    "\n",
    "#Drop insignificant column \"FakeIdentifier\"\n",
    "df.drop('FakeIdentifier', axis=1, inplace=True)\n",
    "\n",
    "#Drop the blank rows input\n",
    "# Remove records where all three GPA components are zero\n",
    "df = df[~((df['UnitsPassednotincludedinGPA'] == 0) &\n",
    "          (df['NumberofClassesEnrolled'] == 0))]\n",
    "\n",
    "#Lets encode categorical data and one hot encode nominal data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "#Encoding Nominal Predictors\n",
    "nominal_cols = ['Gender', 'PrimaryMilitaryAffiliation', 'College',\n",
    "                'UAFullTimePartTime', 'FirstGenerationFlag',\"AcademicCareer\"]\n",
    "df = pd.get_dummies(df, columns=nominal_cols, drop_first=True)\n",
    "\n",
    "#Converting Boolean columns  to int(0/1) type int data\n",
    "bool_cols = df.select_dtypes(include=\"bool\").columns\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Coding Ordinal Predictors\n",
    "df[\"AcademicLevelEndofTerm\"]=df[\"AcademicLevelEndofTerm\"].replace({\"Freshman\": 1, \"Sophomore\": 2,\"Junior\":3,\"Senior\":4 ,\"Graduate\":5 ,\"Masters\":6 })\n",
    "df[\"AcademicYear\"]=df[\"AcademicYear\"].replace({2020: 1, 2021: 2,2022:3,2023:4 ,2024:5 ,2025:6 })\n",
    "\n",
    "#Lets drop highly correlated predictor variables\n",
    "cols = ['College_James E Rogers College of Law', 'UnitsPassedincludedinGPA',\"AcademicCareer_Undergraduate\",\"UAFullTimePartTime_P\"]\n",
    "\n",
    "df.drop(columns=cols, inplace=True)\n",
    "\n",
    "# Define the categorical, ordinal, and numerical columns\n",
    "#categorical_cols = ['Gender', 'PrimaryMilitaryAffiliation', 'College','UAFullTimePartTime', 'FirstGenerationFlag',\"AcademicCareer\"]\n",
    "#ordinal_cols = [\"AcademicLevelEndofTerm\", \"AcademicYear\"]\n",
    "#numerical_cols = [\"Age\",\"NumberofClassesEnrolled\",\"UnitsPassedincludedinGPA\",\"UnitsPassednotincludedinGPA\",\"TermGPA\",\"CumulativeGPA\"]\n",
    "\n",
    "\n",
    "# Create a column transformer to preprocess the data\n",
    "numeric_columns = [\"Age\",\"NumberofClassesEnrolled\",\"UnitsPassednotincludedinGPA\",\"TermGPA\",\"CumulativeGPA\",\"AcademicLevelEndofTerm\", \"AcademicYear\"]\n",
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "\n",
    "\n",
    "# Define the predictor and output variables\n",
    "X = df.drop(columns=[\"CumulativeGPA\"])\n",
    "y = df[\"CumulativeGPA\"]\n",
    "\n",
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.losses import Huber\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "model = Sequential()\n",
    "\n",
    "# New Hidden Layer 1 — 128 neurons\n",
    "model.add(Dense(128, input_shape=(36,), kernel_regularizer=l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Hidden Layer 2 — 64 neurons\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Hidden Layer 3 — 32 neurons\n",
    "model.add(Dense(32, kernel_regularizer=l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Hidden Layer 4 — 16 neurons\n",
    "model.add(Dense(16, kernel_regularizer=l2(0.001)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer — continuous regression output\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the Model\n",
    "# -------------------------\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0008),\n",
    "    loss=Huber(delta=1.0),\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "r2 = r2_score(y_test_inv, y_pred_inv)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R-Squared (R2): {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
